{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr9hA4DbxQpZ0w+y4Dh8TN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaalentinaa/data_engineering_challenge/blob/main/Data_Engineering_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptQlHRn7guU4",
        "outputId": "24774f76-d7cc-401a-a5d5-39010f5f3388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=5c3fac1618afb90c8ba92d14717f9d4714355e5d05f2316c2eec9caf9058c112\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Check Spark Session Information\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "izOryCLfg-vZ",
        "outputId": "b3ec1b90-502d-4e3c-a1c1-9cd808e34438"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fe635ce7af0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7a795acdc321:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvF7wYc1hlur",
        "outputId": "767ac9c0-e005-4638-87de-adc2570c5040"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/data (1).zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IZ6IePmiHFG",
        "outputId": "ab5cc0ff-5b96-40b0-b5d7-8f5c4512ba9a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace ticket_line.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stores = spark.read.csv('stores.csv', header=True, sep=\",\")"
      ],
      "metadata": {
        "id": "znZUcZzyjMIg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04tXdA2TkbOh",
        "outputId": "2a0a62dc-d3df-4069-800c-50c3ff44e5bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+-------+\n",
            "|store_id|country|version|\n",
            "+--------+-------+-------+\n",
            "|      40|     DE|      1|\n",
            "|      41|     DE|      1|\n",
            "|      42|     DE|      1|\n",
            "|      43|     DE|      1|\n",
            "|      44|     DE|      1|\n",
            "|      45|     DE|      1|\n",
            "+--------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products = spark.read.json('products.json')"
      ],
      "metadata": {
        "id": "xyfSxES5kpFp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPyqf5w7lEzz",
        "outputId": "9699fbc1-bfec-4e93-96e2-441376cbab54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------------+\n",
            "|          categories|product_id|        product_name|\n",
            "+--------------------+----------+--------------------+\n",
            "|[{1023, Dairy pro...|         1|        Milbona milk|\n",
            "|[{1023, Dairy pro...|         2|      Milbona cheese|\n",
            "|[{1023, Dairy pro...|         3|       Milbona yogur|\n",
            "|    [{1025, Cereal}]|         4|    Crownfield black|\n",
            "|    [{1025, Cereal}]|         5|Crownfield with milk|\n",
            "|   [{1026, Cookies}]|         6|      Sondey cookeys|\n",
            "|[{1026, Cookies},...|         7|    Sondey digestive|\n",
            "|   [{1026, Cookies}]|         8|    Sondey hazelnuts|\n",
            "|[{1028, Vegetables}]|         9|      Freshona beans|\n",
            "|[{1028, Vegetables}]|        10|   Freshona potatoes|\n",
            "+--------------------+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode"
      ],
      "metadata": {
        "id": "-XCuGZWJ3bx1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "sEvPiac04qHb"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_transformed = products.select(\"product_id\",\"product_name\",explode(\"categories\").category_name)"
      ],
      "metadata": {
        "id": "rZ0bZZp42zZO"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = products_transformed.select(\"product_id\",\"product_name\",col(\"col.category_name\").alias(\"category_name\"),col(\"col.category_id\").alias(\"category_id\"))"
      ],
      "metadata": {
        "id": "zaF2DhYp5hDm"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amp7P7Tt50Eh",
        "outputId": "176ad8db-36b2-4cf8-cf6c-c850192ee91b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-------------+-----------+\n",
            "|product_id|        product_name|category_name|category_id|\n",
            "+----------+--------------------+-------------+-----------+\n",
            "|         1|        Milbona milk|Dairy product|       1023|\n",
            "|         2|      Milbona cheese|Dairy product|       1023|\n",
            "|         3|       Milbona yogur|Dairy product|       1023|\n",
            "|         4|    Crownfield black|       Cereal|       1025|\n",
            "|         5|Crownfield with milk|       Cereal|       1025|\n",
            "|         6|      Sondey cookeys|      Cookies|       1026|\n",
            "|         7|    Sondey digestive|      Cookies|       1026|\n",
            "|         7|    Sondey digestive|       Cereal|       1025|\n",
            "|         8|    Sondey hazelnuts|      Cookies|       1026|\n",
            "|         9|      Freshona beans|   Vegetables|       1028|\n",
            "|        10|   Freshona potatoes|   Vegetables|       1028|\n",
            "+----------+--------------------+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tickets = spark.read.csv('ticket_line.csv',header= True, sep=',')"
      ],
      "metadata": {
        "id": "mY2VyYCzlGli"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tickets.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ8eOhK_llZO",
        "outputId": "df423cc0-0d24-4a86-90d9-08032463885d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+--------+\n",
            "|ticket_id|product_id|store_id|      date|quantity|\n",
            "+---------+----------+--------+----------+--------+\n",
            "|       22|         8|      41|2022-01-02|       3|\n",
            "|      258|         6|      40|2022-01-02|       2|\n",
            "|      623|         2|      45|2022-01-02|       2|\n",
            "|       37|         5|      47|2022-01-02|       2|\n",
            "|      378|         4|      47|2022-01-02|       2|\n",
            "|      391|         1|      46|2022-01-02|       2|\n",
            "|      399|        10|      47|2022-01-02|       3|\n",
            "|      727|         3|      45|2022-01-02|       3|\n",
            "|      994|         2|      44|2022-01-02|       2|\n",
            "|      844|         6|      42|2022-01-02|       3|\n",
            "|      234|        10|      42|2022-01-02|       1|\n",
            "|      206|         7|      44|2022-01-02|       2|\n",
            "|      477|        10|      44|2022-01-02|       3|\n",
            "|      496|         8|      43|2022-01-02|       3|\n",
            "|      586|         1|      47|2022-01-02|       3|\n",
            "|      511|        10|      41|2022-01-02|       3|\n",
            "|      507|         2|      45|2022-01-02|       1|\n",
            "|      271|         6|      43|2022-01-02|       1|\n",
            "|      567|        10|      41|2022-01-02|       3|\n",
            "|      175|         3|      45|2022-01-02|       2|\n",
            "+---------+----------+--------+----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Find how many different stores is each product being sold. Please consider only the stores provided in the store.csv file, as not all stores are included in the Lidl Plus program.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wmqcqkS0oZ6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer using SQL"
      ],
      "metadata": {
        "id": "p3WzowxjqjJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tickets.createOrReplaceTempView(\"EMP\")\n",
        "stores.createOrReplaceTempView(\"STORE\")\n",
        "spark.sql(\"SELECT product_id, count(DISTINCT store_id) as count FROM EMP WHERE store_id IN (SELECT store_id FROM STORE) GROUP BY product_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAg3M4oGl4zQ",
        "outputId": "96048f49-7a7a-427e-928c-3a125f59222d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|product_id|count|\n",
            "+----------+-----+\n",
            "|         7|    6|\n",
            "|         3|    6|\n",
            "|         8|    6|\n",
            "|         5|    6|\n",
            "|         6|    6|\n",
            "|         9|    6|\n",
            "|         1|    6|\n",
            "|        10|    6|\n",
            "|         4|    6|\n",
            "|         2|    6|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer without SQL\n"
      ],
      "metadata": {
        "id": "q-bJY-2kq2-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tickets.join(stores, tickets.store_id == stores.store_id,'inner').groupBy(tickets.product_id,stores.store_id).count().groupBy('product_id').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqWxYD0boz4u",
        "outputId": "4a34767a-8edb-4829-8fa2-50f8ce0e2a2c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|product_id|count|\n",
            "+----------+-----+\n",
            "|         7|    6|\n",
            "|         3|    6|\n",
            "|         8|    6|\n",
            "|         5|    6|\n",
            "|         6|    6|\n",
            "|         9|    6|\n",
            "|         1|    6|\n",
            "|        10|    6|\n",
            "|         4|    6|\n",
            "|         2|    6|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 10 products are being sold in all 6 stores\n"
      ],
      "metadata": {
        "id": "u_81hvjWofoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Calculate the 2nd most selling store for each product as we need a target for advertisement. As the previous one, consider only the stores that are included in the store.csv file."
      ],
      "metadata": {
        "id": "4YDs6Iz0q6s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT product_id, store_id,count(*) as count FROM EMP WHERE store_id IN (SELECT store_id FROM STORE) GROUP BY product_id,store_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKoIkY04mwnk",
        "outputId": "db8688ce-19d3-466b-d521-53b3270738d8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-----+\n",
            "|product_id|store_id|count|\n",
            "+----------+--------+-----+\n",
            "|         2|      40|    8|\n",
            "|         3|      42|   14|\n",
            "|         1|      41|   17|\n",
            "|         1|      42|   17|\n",
            "|         7|      44|   10|\n",
            "|         2|      42|   12|\n",
            "|         4|      42|   17|\n",
            "|         2|      41|   14|\n",
            "|         4|      44|   10|\n",
            "|        10|      45|   15|\n",
            "|         5|      40|   11|\n",
            "|         5|      44|   11|\n",
            "|         8|      44|    9|\n",
            "|         4|      40|   22|\n",
            "|        10|      43|   14|\n",
            "|         3|      43|   17|\n",
            "|         3|      45|   14|\n",
            "|         4|      41|   17|\n",
            "|         3|      44|   15|\n",
            "|         5|      45|   10|\n",
            "+----------+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result and number of purchases in SQL"
      ],
      "metadata": {
        "id": "5SLNXjBIxdqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT product_id,store_id,count\n",
        "FROM (\n",
        "  SELECT product_id, store_id,count(*) AS count,row_number() OVER (\n",
        "          PARTITION BY product_id ORDER BY count(*) DESC\n",
        "      ) rank\n",
        "  FROM EMP\n",
        "  WHERE store_id IN (SELECT store_id FROM STORE)\n",
        "  GROUP BY product_id,store_id\n",
        ")\n",
        "WHERE rank=2 \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BZqO6xVsfqp",
        "outputId": "322c55b9-d641-4d93-a11d-b0a8ed2d7c6f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-----+\n",
            "|product_id|store_id|count|\n",
            "+----------+--------+-----+\n",
            "|         1|      41|   17|\n",
            "|        10|      43|   14|\n",
            "|         2|      41|   14|\n",
            "|         3|      44|   15|\n",
            "|         4|      42|   17|\n",
            "|         5|      41|   13|\n",
            "|         6|      45|   19|\n",
            "|         7|      40|   18|\n",
            "|         8|      41|   11|\n",
            "|         9|      42|   12|\n",
            "+----------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_stores = spark.sql(\"\"\"\n",
        "SELECT product_id,store_id,count\n",
        "FROM (\n",
        "  SELECT product_id, store_id,count(*) AS count,row_number() OVER (\n",
        "          PARTITION BY product_id ORDER BY count(*) DESC\n",
        "      ) rank\n",
        "  FROM EMP\n",
        "  WHERE store_id IN (SELECT store_id FROM STORE)\n",
        "  GROUP BY product_id,store_id\n",
        ")\n",
        "WHERE rank=2 \"\"\")"
      ],
      "metadata": {
        "id": "B3ZTQJVDy2z_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. The marketing team wants to group all these second stores by product category, so they can focus on different stores by using the same advertisement approach. As they don’t care about internal id’s, please provide one row per product category_name and include all the stores within that row."
      ],
      "metadata": {
        "id": "0fdCjK-pyqS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_stores.createOrReplaceTempView(\"SECOND_STORE\")\n",
        "products.createOrReplaceTempView(\"PRODUCTS\")"
      ],
      "metadata": {
        "id": "iK8NuBwFzSUd"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT category_name,concat_ws(',',collect_list(store_id)) AS stores\n",
        "FROM SECOND_STORE\n",
        "LEFT JOIN PRODUCTS ON SECOND_STORE.product_id = PRODUCTS.product_id\n",
        "GROUP BY category_name\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Ssk58gs1dm",
        "outputId": "0b03fb2d-03ac-44c6-ac2f-11f429f05485"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------+\n",
            "|category_name|  stores|\n",
            "+-------------+--------+\n",
            "|       Cereal|42,41,40|\n",
            "|   Vegetables|   43,42|\n",
            "|Dairy product|41,41,44|\n",
            "|      Cookies|45,40,41|\n",
            "+-------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PathQEp0YPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Now, let’s imagine that the integration team is developing a new version for the stores model. They will send this new data for the “version 2” of stores available only for some countries. (That means that you will be receiving both versions simultaneously). They have changed the meaning of store_id and country, so the new store_id has the country prepended to it like “FR99” and the country field is omitted."
      ],
      "metadata": {
        "id": "fU2mcQH6PWBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stores_v2 = spark.read.csv('stores_v2.csv', header=True, sep=\",\")"
      ],
      "metadata": {
        "id": "GbXza_YmPa7E"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_v2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO8nYvgjP1MH",
        "outputId": "53f237c1-3189-4ba1-b70b-b09dd4311d13"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+\n",
            "|store_id|version|\n",
            "+--------+-------+\n",
            "|    DE46|      1|\n",
            "|    DE47|      2|\n",
            "+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split"
      ],
      "metadata": {
        "id": "auIcKcTQP2Q-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_v2 = stores_v2.select(stores_v2.store_id.substr(3,4).alias(\"store_id\"),stores_v2.store_id.substr(1,2).alias(\"country\"),\"version\")"
      ],
      "metadata": {
        "id": "xT91LqSdR48i"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_v2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QyzOv9WU1ec",
        "outputId": "89fbafeb-3cce-40a7-a528-cba9e42e5d9a"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+-------+\n",
            "|store_id|country|version|\n",
            "+--------+-------+-------+\n",
            "|      46|     DE|      1|\n",
            "|      47|     DE|      2|\n",
            "+--------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we just need to concat the 2 versions together"
      ],
      "metadata": {
        "id": "oMsKjbugURCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stores.union(stores_v2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6vvkigmSeH3",
        "outputId": "f32c47c1-104b-4888-b355-c521a7a5cf66"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+-------+\n",
            "|store_id|country|version|\n",
            "+--------+-------+-------+\n",
            "|      40|     DE|      1|\n",
            "|      41|     DE|      1|\n",
            "|      42|     DE|      1|\n",
            "|      43|     DE|      1|\n",
            "|      44|     DE|      1|\n",
            "|      45|     DE|      1|\n",
            "|      46|     DE|      1|\n",
            "|      47|     DE|      2|\n",
            "+--------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And do the same process as before"
      ],
      "metadata": {
        "id": "zusVxT2wVNe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Considering this ETL complete, we need to productize it: prepare it on the version control system, automatically deploy the changes, ensure that there is no software regression on new releases, and check that the process works fine. Which steps would you take?"
      ],
      "metadata": {
        "id": "i2c-mVrjIH8z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IeLhMElaUvfD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}